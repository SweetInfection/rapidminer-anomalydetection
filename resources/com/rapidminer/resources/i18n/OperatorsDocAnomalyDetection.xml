<?xml version="1.0"  encoding="windows-1252" standalone="no"?>
<operatorHelp lang="en_EN">
	<operator>
		<name>k-NN Global Anomaly Score</name>
	   	<synopsis>Calculates the outlier score based on k-nearest-neighbors
	   		implementation.</synopsis>
		<help> <p>
 			This operator calculates the anomaly score based on the k nearest 
 			neighbors implementation. The outlier score is by default the 
 			average of the distance to the nearest neighbors, it can be set to 
 			the distance to the kth nearest neighbor which is similar to the 
 			algorithm proposed by Ramaswamy et al (2000) by setting the 
 			corresponding parameter. The outlier score is calculated according 
 			to the measure type selected. The higher the outlier the more 
 			anomalous the instance is. 
 			
 			The operator is also able to read and write a model containing the k
			nearest neighbors set. Typically, 99% of the execution time is used to
			compute the neighbors such that is a good idea to store the model, for
			example, when looping over a parameter. The operator checks whether the
			model and the ExampleSet fit together. The model can be used for any of
			the nearest-neighbor based algorithms. The parameter k used to create
			the model needs to be the same or larger as the parameter k specified in
			the operator. Otherwise, the model is re-computed.
			</p>
		</help>	
	</operator>
	<operator>
		<name>Local Outlier Factor (LOF)</name>
	   	<synopsis>Calculates the outlier score based on Local Outlier Factor 
	   		implementation, proposed by Breunig et al [1999; 2000].</synopsis>
		<help> <p>	
			The LOF anomaly detection calculates the anomaly score according to 
			the local outlier factor algorithm proposed by Breunig el al.
  			
			LOF is one of the earliest local density based approaches proposed. 
			There are several steps in the calculation of the LOF. The initial 
			step involves getting the nearest neighbors set.The definition of 
			the k-distance employed is the one proposed in the original paper in 
			order to handle duplicates. The definition states that the 
			k-distance(p)   has at least k neighbors  with distinct spatial 
			coordinates that have a distance less than or equal it and at most 
			k-1 of such neighbors with distance strictly less than it.  The 
			reachability distance (reach-dist(p,o)) is the maximum of the 
			distance between point p and o and the k-distance(o). The local 
			reachability is the inverse of the average reachability distance 
			over the nearest neighborhood set. Finally the LOF is   calculated 
			as the average of the ratio of the local reachability  density over 
			the neighborhood set. The values of the LOF oscillates with the 
			change in the size of the neighborhood. Thus a range is defined for 
			the size of the neighborhood. The maximum LOF over that range is 
			taken as the final LOF score. 
 
			A normal instance has an outlier value of approximately 1, while 
			outliers have values greater than 1. 	
			
			The operator is also able to read and write a model containing the k
			nearest neighbors set. Typically, 99% of the execution time is used to
			compute the neighbors such that is a good idea to store the model, for
			example, when looping over a parameter. The operator checks whether the
			model and the ExampleSet fit together. The model can be used for any of
			the nearest-neighbor based algorithms. The parameter k used to create
			the model needs to be the same or larger as the parameter k specified in
			the operator. Otherwise, the model is re-computed.		
 			</p>
		</help>
	</operator>

	<operator>
		<name>Local Outlier Probablity (LoOP)</name>
	   	<synopsis>Calculates the outlier score based on Local Outlier 
	   		Probability, proposed by Kriegel et al [2009].</synopsis>
		<help> <p>
			The LoOP score represents the probability that the object is a local
			density outlier. The algorithm combines the benefits of local 
			density approaches being that it doesn't assume any distribution for
			the data as well as the mathematical concepts of the statistical 
			methods. The Fact that the score is a probability facilitates 
			comparisons. LoOP is also based on the nearest neighbors set. 
			The definition of the k-distance used is the same as the one 
			proposed by Breunig et al [1999; 2000] to handle duplicates.
			
			The operator is also able to read and write a model containing the k
			nearest neighbors set. Typically, 99% of the execution time is used to
			compute the neighbors such that is a good idea to store the model, for
			example, when looping over a parameter. The operator checks whether the
			model and the ExampleSet fit together. The model can be used for any of
			the nearest-neighbor based algorithms. The parameter k used to create
			the model needs to be the same or larger as the parameter k specified in
			the operator. Otherwise, the model is re-computed.
 			</p>
		</help>
	</operator>

	<operator>
		<name>Cluster-Based Local Outlier Factor (CBLOF)</name>
		<synopsis> Calculates the outlier score based on cluster-based local 
			outlier factor proposed by He et al [2003]</synopsis>
		<help> <p>
			CBLOF takes as an input the data set and the cluster model that was 
			generated by a clustering algorithm. It categorizes the clusters 
			into small clusters and large clusters using the parameters alpha 
			and beta.
			
			The anomaly score is then calculated based on the size of the 
			cluster the point belongs to as well as the distance to the nearest 
			large cluster centroid. 
			
			It uses weighting for CBLOF based on the sizes of the clusters as 
			proposed in the original publication. Since this might lead to 
			unexpected behavior (outliers close to small clusters are not found),
			it can be disabled and outliers scores are solely computed based on 
			their distance to the cluster center.
			</p>
		</help>
	</operator>
	<operator>
		<name>Connectivity-Based Outlier Factor (COF)</name>
	   	<synopsis>Calculates the outlier score based on Connectivity Based 
	   	Outlier Factor, proposed by Tang el al [2002]</synopsis>
		<help> <p>
			The COF is a modification of LOF algorithm (Breunig el al, 2000) 
			proposed in order to handle outliers deviating from low density 
			patterns. The definition of the k-distance used is the same as the 
			one proposed by Breunig et al [1999; 2000] to handle duplicates. The 
			normal instances will have an outlier score of approximately 1, 
			while outliers have a value greater than 1.  
			
			The operator is also able to read and write a model containing the k
			nearest neighbors set. Typically, 99% of the execution time is used to
			compute the neighbors such that is a good idea to store the model, for
			example, when looping over a parameter. The operator checks whether the
			model and the ExampleSet fit together. The model can be used for any of
			the nearest-neighbor based algorithms. The parameter k used to create
			the model needs to be the same or larger as the parameter k specified in
			the operator. Otherwise, the model is re-computed.
			</p>
		</help>
	</operator>

	<operator>
		<name>Influenced Outlierness (INFLO)</name>
	   	<synopsis>Calculates the outlier score based on Influenced outlierness,
	   		proposed by Jin et al [2006].</synopsis>
		<help> <p>
			INFLO is a local density method that takes into consideration the 
			neighbors and the reverse neighbors when estimating the local 
			density of a given point. The algorithm is also based on the nearest
			neighbors set.  The definition of the k-distance used is the same as 
			the one proposed by  Breunig et al [1999; 2000] to handle duplicates. 
			The normal instances will have an outlier score of approximately 1, 
			while outliers have a value greater than 1.
			
			The operator is also able to read and write a model containing the k
			nearest neighbors set. Typically, 99% of the execution time is used to
			compute the neighbors such that is a good idea to store the model, for
			example, when looping over a parameter. The operator checks whether the
			model and the ExampleSet fit together. The model can be used for any of
			the nearest-neighbor based algorithms. The parameter k used to create
			the model needs to be the same or larger as the parameter k specified in
			the operator. Otherwise, the model is re-computed.
			</p>
		</help>
	</operator>

	<operator>
		<name>Local Correlation Integeral (LOCI)</name>
	   	<synopsis>Calculates the outlier score based on the Local Correlation 
	   	Integral, proposed by  Papadimitriou et al [2003].</synopsis>
		<help> <p>
			The algorithm has the following advantages over other approaches: 
			The results are not highly affected by the parameters and it 
			provides an automatic statistically intuitive cut off to determine 
			the outliers.

			The computation of the LOCI score requires the calculation of MDEF 
			and &#x3C3;MDEF. MDEF for a point p at radius r refers to the 
			deviation of the density of p to that in its average local 
			neighborhood density. &#x3C3;MDEF is the normalized standard 
			deviation of the point relative to its local neighborhood.

			The original publication suggests the following flagging scheme: The 
			object should be flagged as an outlier if MDEF(p, r, &#x3B1;)&gt;  
			3 *&#x3C3;MDEF(p, r, &#x3B1;). The operator produces an outlier 
			score which corresponds to the maximum ratio between 
			MDEF(p, r, &#x3B1;) and &#x3C3;MDEF(p, r, &#x3B1;) over all r. The 
			higher the ratio the more likely the object is an outlier. The 
			proposed threshold to determine outliers is 3.
			</p> 
		</help>
	</operator>

	<operator>
		<name>approximate Local Correlation Integral (aLOCI)</name>
	   	<synopsis>Calculates the max outlier score based on the approximate 
	   		Local Correlation Integral (aLOCI), proposed by Papadimitriou et al 
	   		[2003].</synopsis>
		<help> <p>
			This algorithm is an approximation to Local Correlation Integer 
			(LOCI) proposed by Papadimitriou et al [2003]. aLOCI provides an 
			automatic statistically intuitive cut off to determine the outliers. 
			The algorithm calculates MDEF and &#x3C3;MDEF for all objects, the 
			outlier score assigned to each object is the maximum ratio between 
			MDEF and &#x3C3;MDEF. To estimate MDEF and &#x3C3;MDEF in a faster 
			way than LOCI, the algorithm uses box counting, using quadtrees the 
			objects in the same cell are considered neighbors for radius equals 
			to the diameter of the cell.
			</p>
		</help>
	</operator>

	<operator>
		<name>Clustering-based Multivariate Gaussian Outlier Score (CMGOS)</name>
	   	<synopsis>Calculates the outlier score based on a clustering result. The
	   		outlier score of an instance depends on the probability of how likely
	   		its distance to the cluster center is. 
	   	</synopsis>
		<help>
			<p>
			This algorithm takes as input a clustered data set and a cluster model
			containing its centroids. Then, an outlier score is calculated on the
			basis of the centroid and the multivariate Gaussian of the cluster.
			Therefore, a covariance matrix of the multivariate Gaussian of each
			cluster is computed. Since covariance matrices are sensitive to outliers,
			different robust estimators exist, whereas this operator has  
			different strategies: (1) Compute covariance matrix, remove outliers
			according to expected percentage and recompute covariance matrix. 
			Basically this could be understood as a multivariate Grubb's Test.
			To cope with the challenge of not invertable matrices, two different
			sub-strategies have been implemented (1a) Reduction - reduces the number
			of dimensions by selecting only dimensions for each cluster which have
			at least two different values and (1a) Regularization - regularizes the covariance
			matrix with lambda (c.f. Friedman, J.H. (1989): Regularized Discriminant Analysis).
			(3) A robust covariance estimation according to 			
			Minimum Covariance Determinant (MCD) by Rousseeuw and Van Driessen as described in
			&quot;A Fast Algorithm for the Minimum Covariance Determinant Estimator&quot;,
			1999, has been implemented. Although the fastMCD was implemented, this
		    algorithm is comparable slow.
			</p>
		</help>
	</operator>

	<operator>
		<name>Generate ROC</name>
	   	<synopsis>ROC based evaluation for unsupervised Anomaly Detection Operators</synopsis>
		<help> <p>
			This operator is for evaluating anomaly detection operators. The basic
			idea is that an anomaly detection algorithm scores the records and this
			operator sorts them by their outlier score and creates a
			Receiver Operator Charateristic (ROC) curve using different outlier
			thresholds. Also, the area under curve (AUC) is computed. A perfect
			anomaly detection algorithm would perfectly separate the outliers from
			the normal instances leading to an AUC of 1.0. If the algorithm just
			guesses the two classes (normal or outlier), a ROC of 0.5 would be
			the result on average. As input, this operator expects the outlier score
			as well as the ground truth as labels.
			Additionally the operator returns the precision and recall values for the whole input data.
			The precision is calculated as true_positives/(true_positives+false_positives).
			The recall is calculated as true_positives/(number of all outliers).
			</p>
		</help>
	</operator>

	<operator>
		<name>Local Density Cluster-Based Outlier Factor (LDCOF)</name>
		<synopsis>Assigns the outlier score according to LDCOF algorithm</synopsis>
		<help> <p>
			This is a local density based anomaly detection algorithm. The 
			anomaly score is set to the distance to the nearest large cluster 
			divided by the average cluster distance of the large cluster. The 
			intuition behind this is that the small clusters are considered 
			outlying and thus they are assigned to the nearest large cluster and 
			this becomes its local neighborhood. The division into large and 
			small clusters can be either done similar to what was implemented 
			in the CBLOF paper (He et al,2003) or it can done in a manner 
			similar to what was proposed in (Moh&#39;d Belal Al- Zoubi,2009). 
			This is determined by the parameter &quot; divide clusters like 
			CBLOF&quot;.
			</p> 
		</help>
	</operator>

	<operator>
		<name>Histogram-based Outlier Score (HBOS)</name>
		<synopsis> Calculates an outlier score by creating an histogram with a fixed 
			or a dynamic binwidth. </synopsis>
		<help> <p>
	  		This operator calculates a separate univariate histogram for every 
	  		column in the Example Set. There are two modes, one with a static 
	  		and one with a dynamic bandwidth. In the static mode every bin has 
	  		the same binwidth equally distributed over the value range. In the 
	  		dynamic mode the binwidth can vary, but you can specify a minimum 
	  		number of examples contained in a bin. The parameter number of bins sets 
	  		the total number of bins used for either mode. The binwidth / minimum number
	  		values per bin is then calculated automatically.
	  		In the dynamic mode it is possible that there are less bins then specified if
	 		some bins contain more than the minimum number of values.
	  		The default values for 
	  		the number of bins is the square root of the number of total examples 
	  		(number of bins set to -1). To compute the outlier 
	  		score, the histograms are normalized to one in height first. Then, 
	  		the score is inverted, so that anomalies have a high score and 
	  		normal examples a low score. It is also possible to apply a 
	  		logarithmic scaling to the score in order to avoid floating point 
	  		precision errors under certain circumstances.
	  		Furthermore, a &quot; ranked mode &quot; can be used for scoring. 
	  		Here, the score is the sum of the ranks of an example among all 
	  		(ordered) histograms instead of using the bin height.
	  		</p>
	 	</help>
	</operator>
<operator>
		<name>One-Class LIBSVM Anomaly Score</name>
		<synopsis>Computes the outlier score using one-class SVMs</synopsis>
		<help> <p> 
		    One-class SVMs are a semi-supervised version of traditional Support Vector 
		    Machines. This operator extends the semi-supervised one-class SVM such that
		    it can be used for unsupervised anomaly detection as proposed by Amer et al. 
		    in &quot;Enhancing One-class Support Vector Machines for Unsupervised 
		    Anomaly Detection&quot; (ODD 2013). The implementation of the algorithm in 
		    the operator is  based on Schoelkopf et al (2001) which attempts to separate
		    the data from the origin using the optimal hyperplane. The decision function 
		    outputs a positive number in case the data is on the side of the hyperplane 
		    away from the origin, negative otherwise. To output a continuous score (Amer 
		    et al, 2013) the score is scaled using the maximum value of the decision 
		    function. The scaling subtracts the decision value of the point from the 
		    maximum, then divides it by the magnitude of the maximum. This results in a
		    score greater than 1.0 for outlying points. Two additional types of one-class
		    SVMs are supported by the operator: robust one-class and eta one-class SVM. 
		    Both of which are proposed by Amer et al (2013) in order to make the one-class 
		    SVMs more robust against outliers for unsupervised anomaly detection.
		    </p>
		</help>
	</operator>	
</operatorHelp>
